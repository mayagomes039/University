{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "def get_cpu_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.cpu_percent(interval=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "start_mem = get_memory_usage()\n",
    "start_cpu = psutil.cpu_percent(interval=1)\n",
    "print(f\"Start mem: {start_mem:.2f} MB\")\n",
    "print(f\"Start cpu: {start_cpu:.2f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = ps.read_csv(\"datasets/state_crime.csv\")\n",
    "minimum_wage = ps.read_csv(\"datasets/min_wage.csv\", encoding=\"cp1252\")\n",
    "wages_by_education = ps.read_csv(\"datasets/wages_by_education.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Valores nulos dataset crime: \", crime.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Valores nulos dataset minimum wage: \", minimum_wage.isna().sum())\n",
    "minimum_wage = minimum_wage.drop(columns=[\"Footnote\", \"Department.Of.Labor.Uncleaned.Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Valores nulos dataset education: \", wages_by_education.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores nulos apenas no dataset sobre minimum_wage nas colunas\n",
    "\n",
    "- Department.Of.Labor.Cleaned.Low.Value.2020.Dollars\n",
    "- Department.Of.Labor.Cleaned.High.Value.2020.Dollars\n",
    "- Footnote\n",
    "\n",
    "No entantanto nesse dataset, valores 0 também são valores nulos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_null = minimum_wage.replace(0, np.nan)\n",
    "#print(\"Valores nulos dataset minimum wage: \", true_null.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substituir valores nulos - Interpolação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['State.Minimum.Wage', 'State.Minimum.Wage.2020.Dollars', \n",
    "            'Department.Of.Labor.Cleaned.Low.Value', 'Department.Of.Labor.Cleaned.Low.Value.2020.Dollars',\n",
    "            'Department.Of.Labor.Cleaned.High.Value', 'Department.Of.Labor.Cleaned.High.Value.2020.Dollars',\n",
    "            ]:\n",
    "    minimum_wage[col] = minimum_wage[col].interpolate(method='linear', limit_direction='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Valores nulos dataset minimum wage: \", minimum_wage.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "def normalize_numerical_columns(df):\n",
    "    pdf = df.to_pandas()\n",
    "    \n",
    "    numerical_columns = pdf.select_dtypes(include=['number']).columns.tolist()\n",
    "    \n",
    "    if 'Year' in numerical_columns:\n",
    "        numerical_columns.remove('Year')\n",
    "    \n",
    "    pdf_scaled = pdf.copy()\n",
    "    pdf_scaled[numerical_columns] = scaler.fit_transform(pdf[numerical_columns])\n",
    "    \n",
    "    return ps.from_pandas(pdf_scaled)\n",
    "\n",
    "minimum_wage_scaled = normalize_numerical_columns(minimum_wage)\n",
    "crime_scaled = normalize_numerical_columns(crime)\n",
    "wages_by_education_scaled = normalize_numerical_columns(wages_by_education)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Valores nulos dataset minimum wage: \", minimum_wage.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = crime.merge(minimum_wage, on=[\"Year\", \"State\"], how=\"outer\")\n",
    "merged_data = merged_data.dropna()\n",
    "merged_data.to_pandas().to_csv(\"datasets/merged_data.csv\", index=False)\n",
    "\n",
    "merged_data = merged_data.rename(columns={'Year': 'year'})\n",
    "merged_data = merged_data.merge(wages_by_education, on=[\"year\"], how=\"outer\")\n",
    "merged_data = merged_data.dropna()\n",
    "merged_data.to_pandas().to_csv(\"datasets/merged_data_2.csv\", index=False)\n",
    "\n",
    "end = time.time()\n",
    "final = end - start\n",
    "\n",
    "end_mem = get_memory_usage()\n",
    "end_cpu = psutil.cpu_percent(interval=1)\n",
    "memory_total = end_mem - start_mem\n",
    "print(f\"Execution time: {final} seconds\")\n",
    "print(f\"Final memory: {end_mem:.2f}\")\n",
    "print(f\"Final cpu: {end_cpu:.2f}\")\n",
    "print(f\"Total memory: {memory_total:.2f} MB\")\n",
    "print(f\"CPU: {get_cpu_usage():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Valores nulos datasets: \", merged_data.isna().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
